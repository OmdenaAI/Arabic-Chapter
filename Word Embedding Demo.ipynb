{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1f1e76-aab8-420a-a32b-5e7793b75aef",
   "metadata": {
    "id": "ca1f1e76-aab8-420a-a32b-5e7793b75aef"
   },
   "source": [
    "<h1>Task 8: Word Embedding</h1>\n",
    "\n",
    "<h4> This notebook compares different embedding methods on a simple task (sentiment analysis) <a href=\"https://www.kaggle.com/mksaad/arabic-sentiment-twitter-corpus\">on a small dataset</a>.</h4>\n",
    "\n",
    "<h4>Table of Contents:</h4>\n",
    "<ol>\n",
    "    <li>Load Dataset</li>\n",
    "    <li>Normalize Dataset</li>\n",
    "    <li>Tokenize Dataset</li>\n",
    "    <li>Word Embedding</li>\n",
    "    <li>Train RNN model</li>\n",
    "    <li>Evaluate model</li>\n",
    "</ol>\n",
    "<h4>Embedding Methods:</h4>\n",
    "<ol>\n",
    "    <li>Genism library's Word2Vec implementation (trained from scratch)</li>\n",
    "    <li>Genism library's fasttext implementation (trained from scratch)</li>\n",
    "    <li>AraVec pretrained embeddings</li>\n",
    "    <li>BERT Arabic pretrained model</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44dd0846-7c49-4358-a38a-43ce6c730c37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44dd0846-7c49-4358-a38a-43ce6c730c37",
    "outputId": "6777836f-e59e-47f2-9ed2-798a9d92416e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import gensim\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from pyarabic import araby\n",
    "from tensorflow.keras.layers import LSTM, GRU, Embedding, Dense, Input, InputLayer, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cd5e5-08d7-4614-97cf-90e86c805069",
   "metadata": {
    "id": "d53cd5e5-08d7-4614-97cf-90e86c805069"
   },
   "source": [
    "<h1>Load Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0753d856-c632-4660-b903-512d7385b43c",
   "metadata": {
    "id": "0753d856-c632-4660-b903-512d7385b43c"
   },
   "outputs": [],
   "source": [
    "train_pos = pd.read_csv(\"data/train_Arabic_tweets_positive_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "train_neg = pd.read_csv(\"data/train_Arabic_tweets_negative_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "test_pos = pd.read_csv(\"data/test_Arabic_tweets_positive_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "test_neg = pd.read_csv(\"data/test_Arabic_tweets_negative_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "train = pd.concat([train_pos, train_neg]).sample(frac=1.0, random_state=0)\n",
    "test = pd.concat([test_pos, test_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf0ac73-68f4-4f33-ad8a-49e161e566dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "abf0ac73-68f4-4f33-ad8a-49e161e566dc",
    "outputId": "edb027e6-18d4-4cc6-df4e-e4d706a0133d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>pos</td>\n",
       "      <td>ÙŠØ³Ù„Ù…ÙˆÙˆ #Ø¢Ø¯Ø¢Ø±ØªÙ†Ø¢ Ù…Ø¢Ù‚ØµØ±ØªÙˆØ¢ Ø¹Ù„Ù‰ Ø¢Ù„Ø¯Ø¹Ù… Ø¢Ù„Ø¬Ù…ÙŠÙ„ ØªÙ…ÙŠØ²...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø¥Ù† ÙÙŠ ØµØ¯Ø±ÙŠ ÙƒÙ„Ø§Ù…Ø§ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ ØªØ±ØªÙŠØ¨Ù‡ ÙÙŠ Ø§Ù„Ø¯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>neg</td>\n",
       "      <td>ÙƒÙ… Ù…Ø±Ù‡ Ù‚Ø¹Ø¯Øª Ù…Ø¹ Ù†Ø§Ø³ Ø§Ùˆ Ø­ØªÙ‰ Ø´Ø®Øµ Ùˆ Ø§Ø³ÙˆÙ„Ù Ù…Ø¹Ø§Ù‡Ù… Ùˆ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§Ø³Ø£Ù„ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ø¸ÙŠÙ… Ø±Ø¨ Ø§Ù„Ø¹Ø±Ø´ Ø§Ù„Ø¹Ø¸ÙŠÙ… Ø§Ù† ÙŠØ´ÙÙŠÙƒ ÙŠ ÙŠØ§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø´ÙŠØ¦Ø§ Ù„Ø·ÙŠÙØ§ ØŒ Ù…ÙØ§Ø¬Ø¦ ØºÙŠØ± Ù…Ø®Ø·Ø· Ù„Ù‡ ØŒ ÙŠØ£ØªÙŠ Ù…Ù†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§Ø°Ø§ Ø§Ù„ÙÙŠÙØ§ Ø¹Ø§Ø±Ù Ù‡Ø§Ù„Ø´ÙŠ ØºÙ„Ø· Ù…Ø´ Ø§Ù„Ù…ÙØ±ÙˆØ¶ ÙŠØªØµØ±Ù ÙˆÙŠØª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ø¬Ø¹Ù„Ù†Ø§ Ù…Ù…Ù† ØªÙØ§Ø¦Ù„ Ø¨Ø®ÙŠØ±Ùƒ ÙØ£ÙƒØ±Ù…ØªÙ‡ ØŒ ÙˆØªÙˆÙƒÙ„ Ø¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>neg</td>\n",
       "      <td>ØµØ¨Ø± Ø§Ù†Ø¸Ù… Ù„ÙƒÙ… Ù…Ù† Ø§Ù„Ø§Ø¨ØªÙˆØ¨ ğŸ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>neg</td>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ ØªÙˆØ­Ø´ØªÙ‡Ø§ Ø§ÙŠØ§ Ø³ÙŠØ¯ÙŠ ÙŠØ§Ù‡ Ø­Ø§Ø¨ÙŠÙ† Ù‡ÙƒØ§ ğŸ˜–</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>pos</td>\n",
       "      <td>Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45275 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet\n",
       "15454   pos  ÙŠØ³Ù„Ù…ÙˆÙˆ #Ø¢Ø¯Ø¢Ø±ØªÙ†Ø¢ Ù…Ø¢Ù‚ØµØ±ØªÙˆØ¢ Ø¹Ù„Ù‰ Ø¢Ù„Ø¯Ø¹Ù… Ø¢Ù„Ø¬Ù…ÙŠÙ„ ØªÙ…ÙŠØ²...\n",
       "10789   pos  Ø§Ù„Ù„Ù‡Ù… Ø¥Ù† ÙÙŠ ØµØ¯Ø±ÙŠ ÙƒÙ„Ø§Ù…Ø§ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ ØªØ±ØªÙŠØ¨Ù‡ ÙÙŠ Ø§Ù„Ø¯...\n",
       "19949   neg  ÙƒÙ… Ù…Ø±Ù‡ Ù‚Ø¹Ø¯Øª Ù…Ø¹ Ù†Ø§Ø³ Ø§Ùˆ Ø­ØªÙ‰ Ø´Ø®Øµ Ùˆ Ø§Ø³ÙˆÙ„Ù Ù…Ø¹Ø§Ù‡Ù… Ùˆ ...\n",
       "12259   neg  Ø§Ø³Ø£Ù„ Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ø¸ÙŠÙ… Ø±Ø¨ Ø§Ù„Ø¹Ø±Ø´ Ø§Ù„Ø¹Ø¸ÙŠÙ… Ø§Ù† ÙŠØ´ÙÙŠÙƒ ÙŠ ÙŠØ§...\n",
       "8704    pos  Ø§Ù„Ù„Ù‡Ù… Ø´ÙŠØ¦Ø§ Ù„Ø·ÙŠÙØ§ ØŒ Ù…ÙØ§Ø¬Ø¦ ØºÙŠØ± Ù…Ø®Ø·Ø· Ù„Ù‡ ØŒ ÙŠØ£ØªÙŠ Ù…Ù†...\n",
       "...     ...                                                ...\n",
       "7642    neg  Ø§Ø°Ø§ Ø§Ù„ÙÙŠÙØ§ Ø¹Ø§Ø±Ù Ù‡Ø§Ù„Ø´ÙŠ ØºÙ„Ø· Ù…Ø´ Ø§Ù„Ù…ÙØ±ÙˆØ¶ ÙŠØªØµØ±Ù ÙˆÙŠØª...\n",
       "21243   pos  Ø§Ù„Ù„Ù‡Ù… Ø§Ø¬Ø¹Ù„Ù†Ø§ Ù…Ù…Ù† ØªÙØ§Ø¦Ù„ Ø¨Ø®ÙŠØ±Ùƒ ÙØ£ÙƒØ±Ù…ØªÙ‡ ØŒ ÙˆØªÙˆÙƒÙ„ Ø¹...\n",
       "19852   neg                          ØµØ¨Ø± Ø§Ù†Ø¸Ù… Ù„ÙƒÙ… Ù…Ù† Ø§Ù„Ø§Ø¨ØªÙˆØ¨ ğŸ˜\n",
       "20806   neg             ÙˆØ§Ù„Ù„Ù‡ ØªÙˆØ­Ø´ØªÙ‡Ø§ Ø§ÙŠØ§ Ø³ÙŠØ¯ÙŠ ÙŠØ§Ù‡ Ø­Ø§Ø¨ÙŠÙ† Ù‡ÙƒØ§ ğŸ˜–\n",
       "2732    pos  Ø¨Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ù‡Ù„Ø§Ù„ .. ğŸ’™ Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ø¢ÙŠÙÙˆÙ† XRğŸ“± Ø±ØªÙˆÙŠ...\n",
       "\n",
       "[45275 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec34d35c-034b-4d11-8ea6-6767653d47b6",
   "metadata": {
    "id": "ec34d35c-034b-4d11-8ea6-6767653d47b6"
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = araby.strip_harakat(text)\n",
    "    text = araby.strip_tashkeel(text)\n",
    "    text = araby.strip_small(text)\n",
    "    text = araby.strip_tatweel(text)\n",
    "    text = araby.strip_shadda(text)\n",
    "    text = araby.strip_diacritics(text)\n",
    "    text = araby.normalize_ligature(text)\n",
    "    #text = araby.normalize_hamza(text)\n",
    "    text = araby.normalize_teh(text)\n",
    "    text = araby.normalize_alef(text)\n",
    "    return text\n",
    "\n",
    "def strip_all(text):\n",
    "    l = [' ', '0', '1', '2', '3', '4', '5', '6',\n",
    "       '7', '8', '9', '?', \n",
    "       'ØŸ', 'Ø¡', 'Ø¤', 'Ø¦', 'Ø§', 'Ø¨', 'Øª', 'Ø«',\n",
    "       'Ø¬', 'Ø­', 'Ø®', 'Ø¯', 'Ø°', 'Ø±', 'Ø²', 'Ø³', 'Ø´', 'Øµ', 'Ø¶', 'Ø·', 'Ø¸',\n",
    "       'Ø¹', 'Øº', 'Ù', 'Ù‚', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ù‡', 'Ùˆ', 'ÙŠ', 'Ù ', 'Ù¡',\n",
    "       'Ù¢', 'Ù£', 'Ù¤', 'Ù¥', 'Ù¦', 'Ù§', 'Ù¨', 'Ù©']\n",
    "    return \"\".join([x for x in text if x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea115c1-fddf-49f7-ba66-db45bff6c844",
   "metadata": {
    "id": "6ea115c1-fddf-49f7-ba66-db45bff6c844"
   },
   "outputs": [],
   "source": [
    "train.tweet = train.tweet.apply(normalize).apply(strip_all).apply(araby.tokenize)\n",
    "test.tweet = test.tweet.apply(normalize).apply(strip_all).apply(araby.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b6b7fb-6f01-4b77-9334-65fd3d346dc1",
   "metadata": {
    "id": "e5b6b7fb-6f01-4b77-9334-65fd3d346dc1"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train.label)\n",
    "train.label = le.transform(train.label)\n",
    "test.label = le.transform(test.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9c3e9a-66e2-45fa-915e-2475f3785d62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "9e9c3e9a-66e2-45fa-915e-2475f3785d62",
    "outputId": "ba0f908d-ca2e-40aa-8ef2-124b00d16f2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>1</td>\n",
       "      <td>[ÙŠØ³Ù„Ù…ÙˆÙˆ, Ø§Ø¯Ø§Ø±ØªÙ†Ø§, Ù…Ø§Ù‚ØµØ±ØªÙˆØ§, Ø¹Ù„Ø§, Ø§Ù„Ø¯Ø¹Ù…, Ø§Ù„Ø¬Ù…ÙŠÙ„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>1</td>\n",
       "      <td>[Ø§Ù„Ù„Ù‡Ù…, Ø§Ù†, ÙÙŠ, ØµØ¯Ø±ÙŠ, ÙƒÙ„Ø§Ù…Ø§, Ù„Ø§, Ø§Ø³ØªØ·ÙŠØ¹, ØªØ±ØªÙŠØ¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>0</td>\n",
       "      <td>[ÙƒÙ…, Ù…Ø±Ù‡, Ù‚Ø¹Ø¯Øª, Ù…Ø¹, Ù†Ø§Ø³, Ø§Ùˆ, Ø­ØªØ§, Ø´Ø®Øµ, Ùˆ, Ø§Ø³ÙˆÙ„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>0</td>\n",
       "      <td>[Ø§Ø³Ø§Ù„, Ø§Ù„Ù„Ù‡, Ø§Ù„Ø¹Ø¸ÙŠÙ…, Ø±Ø¨, Ø§Ù„Ø¹Ø±Ø´, Ø§Ù„Ø¹Ø¸ÙŠÙ…, Ø§Ù†, ÙŠØ´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>1</td>\n",
       "      <td>[Ø§Ù„Ù„Ù‡Ù…, Ø´ÙŠØ¦Ø§, Ù„Ø·ÙŠÙØ§, Ù…ÙØ§Ø¬Ø¦, ØºÙŠØ±, Ù…Ø®Ø·Ø·, Ù„Ù‡, ÙŠØ§Øª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>0</td>\n",
       "      <td>[Ø§Ø°Ø§, Ø§Ù„ÙÙŠÙØ§, Ø¹Ø§Ø±Ù, Ù‡Ø§Ù„Ø´ÙŠ, ØºÙ„Ø·, Ù…Ø´, Ø§Ù„Ù…ÙØ±ÙˆØ¶, ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>1</td>\n",
       "      <td>[Ø§Ù„Ù„Ù‡Ù…, Ø§Ø¬Ø¹Ù„Ù†Ø§, Ù…Ù…Ù†, ØªÙØ§Ø¦Ù„, Ø¨Ø®ÙŠØ±Ùƒ, ÙØ§ÙƒØ±Ù…ØªÙ‡, ÙˆØª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>0</td>\n",
       "      <td>[ØµØ¨Ø±, Ø§Ù†Ø¸Ù…, Ù„ÙƒÙ…, Ù…Ù†, Ø§Ù„Ø§Ø¨ØªÙˆØ¨]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>0</td>\n",
       "      <td>[ÙˆØ§Ù„Ù„Ù‡, ØªÙˆØ­Ø´ØªÙ‡Ø§, Ø§ÙŠØ§, Ø³ÙŠØ¯ÙŠ, ÙŠØ§Ù‡, Ø­Ø§Ø¨ÙŠÙ†, Ù‡ÙƒØ§]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>1</td>\n",
       "      <td>[Ø¨Ù…Ù†Ø§Ø³Ø¨Ù‡, ÙÙˆØ², Ø§Ù„Ù‡Ù„Ø§Ù„, Ø³Ø­Ø¨, Ø¹Ù„Ø§, Ø§ÙŠÙÙˆÙ†, Ø±ØªÙˆÙŠØª,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45275 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "15454      1  [ÙŠØ³Ù„Ù…ÙˆÙˆ, Ø§Ø¯Ø§Ø±ØªÙ†Ø§, Ù…Ø§Ù‚ØµØ±ØªÙˆØ§, Ø¹Ù„Ø§, Ø§Ù„Ø¯Ø¹Ù…, Ø§Ù„Ø¬Ù…ÙŠÙ„...\n",
       "10789      1  [Ø§Ù„Ù„Ù‡Ù…, Ø§Ù†, ÙÙŠ, ØµØ¯Ø±ÙŠ, ÙƒÙ„Ø§Ù…Ø§, Ù„Ø§, Ø§Ø³ØªØ·ÙŠØ¹, ØªØ±ØªÙŠØ¨...\n",
       "19949      0  [ÙƒÙ…, Ù…Ø±Ù‡, Ù‚Ø¹Ø¯Øª, Ù…Ø¹, Ù†Ø§Ø³, Ø§Ùˆ, Ø­ØªØ§, Ø´Ø®Øµ, Ùˆ, Ø§Ø³ÙˆÙ„...\n",
       "12259      0  [Ø§Ø³Ø§Ù„, Ø§Ù„Ù„Ù‡, Ø§Ù„Ø¹Ø¸ÙŠÙ…, Ø±Ø¨, Ø§Ù„Ø¹Ø±Ø´, Ø§Ù„Ø¹Ø¸ÙŠÙ…, Ø§Ù†, ÙŠØ´...\n",
       "8704       1  [Ø§Ù„Ù„Ù‡Ù…, Ø´ÙŠØ¦Ø§, Ù„Ø·ÙŠÙØ§, Ù…ÙØ§Ø¬Ø¦, ØºÙŠØ±, Ù…Ø®Ø·Ø·, Ù„Ù‡, ÙŠØ§Øª...\n",
       "...      ...                                                ...\n",
       "7642       0  [Ø§Ø°Ø§, Ø§Ù„ÙÙŠÙØ§, Ø¹Ø§Ø±Ù, Ù‡Ø§Ù„Ø´ÙŠ, ØºÙ„Ø·, Ù…Ø´, Ø§Ù„Ù…ÙØ±ÙˆØ¶, ÙŠ...\n",
       "21243      1  [Ø§Ù„Ù„Ù‡Ù…, Ø§Ø¬Ø¹Ù„Ù†Ø§, Ù…Ù…Ù†, ØªÙØ§Ø¦Ù„, Ø¨Ø®ÙŠØ±Ùƒ, ÙØ§ÙƒØ±Ù…ØªÙ‡, ÙˆØª...\n",
       "19852      0                      [ØµØ¨Ø±, Ø§Ù†Ø¸Ù…, Ù„ÙƒÙ…, Ù…Ù†, Ø§Ù„Ø§Ø¨ØªÙˆØ¨]\n",
       "20806      0       [ÙˆØ§Ù„Ù„Ù‡, ØªÙˆØ­Ø´ØªÙ‡Ø§, Ø§ÙŠØ§, Ø³ÙŠØ¯ÙŠ, ÙŠØ§Ù‡, Ø­Ø§Ø¨ÙŠÙ†, Ù‡ÙƒØ§]\n",
       "2732       1  [Ø¨Ù…Ù†Ø§Ø³Ø¨Ù‡, ÙÙˆØ², Ø§Ù„Ù‡Ù„Ø§Ù„, Ø³Ø­Ø¨, Ø¹Ù„Ø§, Ø§ÙŠÙÙˆÙ†, Ø±ØªÙˆÙŠØª,...\n",
       "\n",
       "[45275 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "environmental-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word, word_model):\n",
    "    return word_model.wv.key_to_index[word]\n",
    "def idx2word(idx):\n",
    "    return word_model.wv.index_to_key[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fresh-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00ed07d-8036-4e61-a7d9-bbefb19384d4",
   "metadata": {
    "id": "e00ed07d-8036-4e61-a7d9-bbefb19384d4"
   },
   "outputs": [],
   "source": [
    "def token2vec(word_model, data):\n",
    "    data_tmp = np.zeros([data.shape[0], 100], dtype=np.int32)\n",
    "    for i, sentence in enumerate(data):\n",
    "        for t, word in enumerate(sentence[:100]):\n",
    "            if word in word_model.wv.key_to_index:\n",
    "                data_tmp[i, t] = word2idx(word, word_model)\n",
    "            else:\n",
    "                data_tmp[i, t] = 0\n",
    "    return data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f81eee-3188-44cf-b1c1-06c0a9d5b7ef",
   "metadata": {
    "id": "00f81eee-3188-44cf-b1c1-06c0a9d5b7ef"
   },
   "outputs": [],
   "source": [
    "def train_model(vocab_size, embedding_size, weights):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[weights], trainable=True))\n",
    "    model.add(Bidirectional(GRU(units = 32, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(units = 32, return_sequences=False)))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\n",
    "    model.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 5, batch_size= 128, shuffle = True, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ba0efc-2a73-480a-ba4f-92839c6c0ca3",
   "metadata": {
    "id": "b6ba0efc-2a73-480a-ba4f-92839c6c0ca3"
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([train.tweet.values, test.tweet.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd0caf2-82aa-4b02-bb30-dedefe14ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_cbow = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4, seed=0)\n",
    "word2vec_model_cbow.build_vocab(sentences) \n",
    "word2vec_model_cbow.train(sentences, total_examples=word2vec_model_cbow.corpus_count, epochs=15)\n",
    "word2vec_weights_cbow = word2vec_model_cbow.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights_cbow.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30c10f2d-86f5-43c4-9eec-971a95a8eb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠÙ‡', 0.6934918165206909),\n",
       " ('Ø§Ø­ÙŠØ§Ù†Ø§', 0.6874623894691467),\n",
       " ('Ø­ÙƒØ§ÙŠÙ‡', 0.6851267218589783),\n",
       " ('Ø§Ù„ÙƒØªÙ…Ø§Ù†', 0.676027774810791),\n",
       " ('Ø¨ÙƒØ±Ø§Ù…Ù‡', 0.6758304238319397),\n",
       " ('Ø§Ù„Ù…ÙˆØ¬Ø¹Ù‡', 0.6753607988357544),\n",
       " ('Ù„Ø§Ù†Ø§', 0.6732767820358276),\n",
       " ('Ù†Ø¯Ø§', 0.6690214276313782),\n",
       " ('Ø§Ø±ÙˆØ§Ø­', 0.6672318577766418),\n",
       " ('ÙŠØ­Ø³ÙˆÙ†', 0.6625495553016663)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model_cbow.wv.most_similar(\"Ù„ØºÙ‡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "593f78d2-520a-4e24-8767-16daec4e2edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ù…ÙØ±Ø¯Ø§Øª', 0.7585998177528381),\n",
       " ('Ù„ØºØ§Øª', 0.755275309085846),\n",
       " ('ÙˆÙ„ØºÙ‡', 0.7323259711265564),\n",
       " ('Ø§Ø¨Ø¬Ø¯ÙŠÙ‡', 0.7260634899139404),\n",
       " ('Ù…ØµØ·Ù„Ø­Ø§Øª', 0.7094709873199463),\n",
       " ('Ø§Ù„Ù„ØºÙ‡', 0.7051507234573364),\n",
       " ('Ø§Ø¨Ø¬Ø¯ÙŠØ§Øª', 0.6975376605987549),\n",
       " ('Ø¨Ù„ØºÙ‡', 0.6946367025375366),\n",
       " ('Ù„ØºØªÙ‡Ø§', 0.6932260394096375),\n",
       " ('Ø«Ù‚Ø§ÙÙ‡', 0.6907159090042114)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model = aravec.load_model(\"full_grams_cbow_100_twitter/full_grams_cbow_100_twitter.mdl\")\n",
    "model.wv.most_similar(\"Ù„ØºÙ‡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ed6f2e-e8d2-4b25-ac8d-3a786b7b4578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3ed6f2e-e8d2-4b25-ac8d-3a786b7b4578",
    "outputId": "05ee279e-c12d-4f79-a392-b8f0d0018202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 16s 70ms/step - loss: 0.6142 - accuracy: 0.6511 - val_loss: 0.5274 - val_accuracy: 0.7279\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.4243 - accuracy: 0.8073 - val_loss: 0.4828 - val_accuracy: 0.7583\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.2309 - accuracy: 0.9120 - val_loss: 0.5850 - val_accuracy: 0.7621\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 12s 70ms/step - loss: 0.1334 - accuracy: 0.9549 - val_loss: 0.7050 - val_accuracy: 0.7574\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.0827 - accuracy: 0.9724 - val_loss: 0.8357 - val_accuracy: 0.7586\n"
     ]
    }
   ],
   "source": [
    "word2vec_model_cbow = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4, seed=0)\n",
    "word2vec_model_cbow.build_vocab(sentences) \n",
    "word2vec_model_cbow.train(sentences, total_examples=word2vec_model_cbow.corpus_count, epochs=15)\n",
    "word2vec_weights_cbow = word2vec_model_cbow.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights_cbow.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(word2vec_model_cbow, X_train)\n",
    "X_valid = token2vec(word2vec_model_cbow, X_valid)\n",
    "\n",
    "trained_word2vec_cbow = train_model(vocab_size, emdedding_size, word2vec_weights_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d689b554-b3d7-4a43-9649-f071745a6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 17s 71ms/step - loss: 0.6154 - accuracy: 0.6542 - val_loss: 0.5518 - val_accuracy: 0.7089\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.4851 - accuracy: 0.7635 - val_loss: 0.4901 - val_accuracy: 0.7495\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.3172 - accuracy: 0.8631 - val_loss: 0.5052 - val_accuracy: 0.7645\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.1694 - accuracy: 0.9341 - val_loss: 0.6379 - val_accuracy: 0.7621\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.0928 - accuracy: 0.9672 - val_loss: 0.7804 - val_accuracy: 0.7635\n"
     ]
    }
   ],
   "source": [
    "word2vec_model_sg = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4, seed=0, sg=1)\n",
    "word2vec_model_sg.build_vocab(sentences) \n",
    "word2vec_model_sg.train(sentences, total_examples=word2vec_model_sg.corpus_count, epochs=15)\n",
    "word2vec_weights_sg = word2vec_model_sg.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights_sg.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(word2vec_model_sg, X_train)\n",
    "X_valid = token2vec(word2vec_model_sg, X_valid)\n",
    "\n",
    "trained_word2vec_sg = train_model(vocab_size, emdedding_size, word2vec_weights_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22645e1-3541-4909-81c0-3b1ebd0710b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f22645e1-3541-4909-81c0-3b1ebd0710b4",
    "outputId": "7f98e2d1-8884-4ae2-bfdb-811596ff25bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 16s 69ms/step - loss: 0.6071 - accuracy: 0.6525 - val_loss: 0.5213 - val_accuracy: 0.7268\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 0.4151 - accuracy: 0.8100 - val_loss: 0.4658 - val_accuracy: 0.7661\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.2260 - accuracy: 0.9111 - val_loss: 0.5864 - val_accuracy: 0.7700\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 0.1271 - accuracy: 0.9549 - val_loss: 0.7278 - val_accuracy: 0.7650\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 0.0724 - accuracy: 0.9755 - val_loss: 0.8025 - val_accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = gensim.models.FastText(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "fasttext_model.build_vocab(sentences)\n",
    "fasttext_model.train(sentences, total_examples=fasttext_model.corpus_count, epochs=15) \n",
    "fasttext_weights = fasttext_model.syn1neg\n",
    "vocab_size, emdedding_size = fasttext_weights.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(fasttext_model, X_train)\n",
    "X_valid = token2vec(fasttext_model, X_valid)\n",
    "\n",
    "trained_fasttext = train_model(vocab_size, emdedding_size, fasttext_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b17894-1140-4e18-a870-6ab8cc925d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab = np.unique(np.array([x for y in train.tweet.values for x in y ]))\n",
    "word_index = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "seq_list = []\n",
    "for words in train.tweet.values:\n",
    "    seq = []\n",
    "    for w in words:\n",
    "        seq.append(word_index.get(w,0))\n",
    "    seq_list.append(seq)\n",
    "train_padded = pad_sequences(seq_list, padding=\"post\", truncating=\"post\", maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7d100e-37a0-4649-a0d1-115208fbac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 17s 68ms/step - loss: 0.6055 - accuracy: 0.6737 - val_loss: 0.5433 - val_accuracy: 0.7218\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 0.5080 - accuracy: 0.7530 - val_loss: 0.5041 - val_accuracy: 0.7449\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 0.4164 - accuracy: 0.8111 - val_loss: 0.4854 - val_accuracy: 0.7673\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 0.3220 - accuracy: 0.8582 - val_loss: 0.5181 - val_accuracy: 0.7733\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 0.2401 - accuracy: 0.8987 - val_loss: 0.5903 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model_path = aravec.get_model(\"Twitter_CBOW_100\", unzip=True)\n",
    "model = aravec.load_model(model_path)\n",
    "\n",
    "embeddings_index = aravec.get_embedding_matrix(model)\n",
    "vocab_size, emdedding_size = len(word_index),100\n",
    "embeddings_matrix = aravec.load_embedding_matrix(vocab_size, emdedding_size, word_index, embeddings_index)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_padded, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "trained_cbow = train_model(vocab_size, emdedding_size, embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marine-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 19s 72ms/step - loss: 0.6165 - accuracy: 0.6501 - val_loss: 0.5195 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 0.4561 - accuracy: 0.7857 - val_loss: 0.4653 - val_accuracy: 0.7718\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 0.3203 - accuracy: 0.8620 - val_loss: 0.5041 - val_accuracy: 0.7753\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 13s 72ms/step - loss: 0.1999 - accuracy: 0.9234 - val_loss: 0.6139 - val_accuracy: 0.7686\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 0.1110 - accuracy: 0.9621 - val_loss: 0.7417 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model_path = aravec.get_model(\"Twitter_SkipGram_100\", unzip=True)\n",
    "model = aravec.load_model(model_path)\n",
    "\n",
    "embeddings_index = aravec.get_embedding_matrix(model)\n",
    "vocab_size, emdedding_size = len(word_index),100\n",
    "embeddings_matrix = aravec.load_embedding_matrix(vocab_size, emdedding_size, word_index, embeddings_index)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_padded, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "trained_skipgram = train_model(vocab_size, emdedding_size, embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2LA1_FOLJfco",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LA1_FOLJfco",
    "outputId": "3181e854-802d-49ae-fe8a-046a88ac908a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed datasets-1.7.0 fsspec-2021.5.0 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1070c0f1-e12d-4c72-b4da-adeabde772a8",
   "metadata": {
    "id": "1070c0f1-e12d-4c72-b4da-adeabde772a8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "train = pd.concat([train_pos, train_neg])\n",
    "test = pd.concat([test_pos, test_neg])\n",
    "train.tweet = train.tweet.apply(normalize).apply(strip_all)\n",
    "test.tweet = test.tweet.apply(normalize).apply(strip_all)\n",
    "train.label = le.transform(train.label)\n",
    "test.label = le.transform(test.label)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet, train.label, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-medium-arabic\")\n",
    "\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding='max_length', max_length=100)\n",
    "val_encodings = tokenizer(X_valid.tolist(), truncation=True, padding='max_length', max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec61b626-2b8c-4c8e-9299-d48b299777b4",
   "metadata": {
    "id": "ec61b626-2b8c-4c8e-9299-d48b299777b4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MeterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MeterDataset(train_encodings, y_train.tolist())\n",
    "val_dataset = MeterDataset(val_encodings, y_valid.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d482df79-717e-430f-a461-a4aa0593fefe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "8a1c523e5a234220a6f0e1deab0e0083",
      "252b6a14984545a684aeaff90818c2ae",
      "ede198ccc18446b3a021f8f0d21294ff",
      "8fb5dd2f07cb4dcaad0a5d7dac81485f",
      "2dc4fa91529047369720a951d77e39e6",
      "1171428605b143d1bc00cee9e3ded25b",
      "b670450c54df49c7959a58a55ccd977d",
      "efd9a8f7521946f0b04681246bf6fb58"
     ]
    },
    "id": "d482df79-717e-430f-a461-a4aa0593fefe",
    "outputId": "6cb2d23a-c07d-41e1-e3ca-c00f2b94f180"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at asafaya/bert-medium-arabic were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-medium-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the latest cached version of the module from /home/mmi333/.cache/huggingface/modules/datasets_modules/metrics/accuracy/d60e08bd37e7c5a7bcc3620dd0d2788d25d233238ee0bdb3cfabde6c43d60574 (last modified on Wed Jun  2 15:47:30 2021) since it couldn't be found locally at accuracy/accuracy.py or remotely (ConnectionError).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2832' max='2832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2832/2832 16:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.540600</td>\n",
       "      <td>0.499445</td>\n",
       "      <td>0.745251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.486501</td>\n",
       "      <td>0.770960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.570267</td>\n",
       "      <td>0.766543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.751087</td>\n",
       "      <td>0.767073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2832, training_loss=0.33862685039639473, metrics={'train_runtime': 1008.9977, 'train_samples_per_second': 2.807, 'total_flos': 268079209398000.0, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 1894203392, 'init_mem_gpu_alloc_delta': 168528384, 'init_mem_cpu_peaked_delta': 64856064, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 20869120, 'train_mem_gpu_alloc_delta': 506130432, 'train_mem_cpu_peaked_delta': 130834432, 'train_mem_gpu_peaked_delta': 1205711360})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"asafaya/bert-medium-arabic\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=32,              # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,           # strength of weight decay\n",
    "    learning_rate= 5e-5,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy = 'epoch',\n",
    ")\n",
    "from datasets import load_metric\n",
    "from transformers import Trainer\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51966f6c-74cf-4467-b423-9edc0922e511",
   "metadata": {
    "id": "51966f6c-74cf-4467-b423-9edc0922e511"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1171428605b143d1bc00cee9e3ded25b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "252b6a14984545a684aeaff90818c2ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dc4fa91529047369720a951d77e39e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8a1c523e5a234220a6f0e1deab0e0083": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ede198ccc18446b3a021f8f0d21294ff",
       "IPY_MODEL_8fb5dd2f07cb4dcaad0a5d7dac81485f"
      ],
      "layout": "IPY_MODEL_252b6a14984545a684aeaff90818c2ae"
     }
    },
    "8fb5dd2f07cb4dcaad0a5d7dac81485f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd9a8f7521946f0b04681246bf6fb58",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b670450c54df49c7959a58a55ccd977d",
      "value": " 170M/170M [00:09&lt;00:00, 18.5MB/s]"
     }
    },
    "b670450c54df49c7959a58a55ccd977d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ede198ccc18446b3a021f8f0d21294ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1171428605b143d1bc00cee9e3ded25b",
      "max": 169735531,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2dc4fa91529047369720a951d77e39e6",
      "value": 169735531
     }
    },
    "efd9a8f7521946f0b04681246bf6fb58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
